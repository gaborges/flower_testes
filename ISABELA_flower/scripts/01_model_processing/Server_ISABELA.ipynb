{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9018ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 15:13:31.924012: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 15:13:32.073043: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-19 15:13:32.518374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-19 15:13:32.518490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-19 15:13:32.518498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from flwr.common.logger import log\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import (\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    MetricsAggregationFn,\n",
    "    NDArrays,\n",
    "    Parameters,\n",
    "    Scalar,\n",
    "    ndarrays_to_parameters,\n",
    "    parameters_to_ndarrays,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a82cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolders = \"../data_2019_processed/\"\n",
    "# selected features\n",
    "inputFeatures = [\"activity\",\"location\",\"day_of_week\",\"light\",\"phone_lock\",\"proximity\",\"sound\",\"time_to_next_alarm\", \"minutes_day\"]\n",
    "outputClasses = [\"awake\",\"asleep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e192aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadTestData(dataSet):\n",
    "    print(len(dataSet), \"datasets\")\n",
    "    for i in range(0,len(dataSet)):\n",
    "        print(i , \"-\", dataSet[i])\n",
    "        #print(trainingDataSet[i])\n",
    "        if(i == 0):\n",
    "            X_test = pd.read_csv(inputFolders+\"student_\"+dataSet[i]+\"_transformed.csv\")\n",
    "        else:\n",
    "            dataset = pd.read_csv(inputFolders+\"student_\"+dataSet[i]+\"_transformed.csv\")\n",
    "            X_test = pd.concat([X_test, dataset])\n",
    "    # return the dataset        \n",
    "    return X_test\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_nominal_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data['awake']\n",
    "    dataset['asleep'] = one_hot_encoded_data['asleep']\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# one-hot encoding function\n",
    "def transform_output_numerical_class_into_one_hot_encoding(dataset):\n",
    "    # create two classes based on the single class\n",
    "    one_hot_encoded_data = pd.get_dummies(dataset['class'])\n",
    "    #print(one_hot_encoded_data)\n",
    "    dataset['awake'] = one_hot_encoded_data[0]\n",
    "    dataset['asleep'] = one_hot_encoded_data[1]\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def transform_data_type(dataframe):\n",
    "    \n",
    "    # transform inputs\n",
    "    for column in inputFeatures:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    # transform outputs\n",
    "    for column in outputClasses:\n",
    "        dataframe[column] = dataframe[column].astype('float32')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c41101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
    "\n",
    "            # Save aggregated_ndarrays\n",
    "            print(f\"Saving round {server_round} aggregated_ndarrays...\")\n",
    "            np.savez(f\"round-{server_round}-weights.npz\", *aggregated_ndarrays)\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02daf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Keep batch size fixed at 32, perform two rounds of training with one\n",
    "    local epoch, increase to two local epochs afterwards.\n",
    "    \"\"\"\n",
    "    print(\"onn fit\")\n",
    "    config = {\n",
    "        \"batch_size\": 32,\n",
    "        \"local_epochs\": 1,\n",
    "    }\n",
    "    return config\n",
    "\t\n",
    "\t\n",
    "def get_evaluate_fn(model):\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    \n",
    "    testFolders =  [#'0Jf4TH9Zzse0Z1Jjh7SnTOe2MMzeSnFi7feTnkG6vgs',\n",
    "                #'0tdmm6rwW3KquQ73ATYYJ5JkpMtvbppJ0VzA2GExdA', \n",
    "                #'2cyV53lVyUtlMj0BRwilEWtYJwUiviYoL48cZBPBq0', \n",
    "                #'2J22RukYnEbKTk7t+iUVDBkorcyL5NKN6TrLe89ys', \n",
    "                #['5FLZBTVAPwdq9QezHE2sVCJIs7p+r6mCemA2gp9jATk'], #does not have the file\n",
    "                #'7EYF5I04EVqisUJCVNHlqn77UAuOmwL2Dahxd3cA', \n",
    "                #'a9Qgj8ENWrHvl9QqlXcIPKmyGMKgbfHk9Dbqon1HQP4', \n",
    "                #'ae4JJBZDycEcY8McJF+3BxyvZ1619y03BNdCxzpZTc', \n",
    "                #'Ch3u5Oaz96VSrQbf0z31X6jEIbeIekkC0mwPzCdeJ1U', \n",
    "                #'CH8f0yZkZL13zWuE9ks1CkVJRVrr+jsGdUXHrZ6YeA', \n",
    "                #'DHO1K4jgiwZJOfQTrxvKE2vn7hkjamigroGD5IaeRc', \n",
    "                #'DHPqzSqSttiba1L3BD1cptNJPjSxZ8rXxF9mY3za6WA', # does not have asleep data\n",
    "                #'dQEFscjqnIlug8Tgq97JohhSQPG2DEOWJqS86wCrcY', \n",
    "                #'HFvs2CohmhHte+AaCzFasjzegGzxZKPhkrX23iI6Xo', \n",
    "                #'jgB9E8v3Z6PKdTRTCMAijBllA9YEMtrmHbe4qsbmJWw', \n",
    "                #'JkY++R7E8myldLN3on6iQ78Ee78zCbrLuggfwGju3I', \n",
    "                #'K4SLohf+TN1Ak8Dn8iE3Lme7rEMPISfppB2sXfHX8', \n",
    "                #'oGaWetJJJEWHuvYdWYo826SQxfhCExVVQ2da8LE1Y7Q', \n",
    "                #'pyt24oiDAHsmgWMvkFKz2fn2pwcHiXchd6KchLM', \n",
    "                'PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc', # does not have asleep data\n",
    "                #'QUNCATForxzK0HHw46LrGOMWh0eVA8Y5XWEiUXX+cQ', \n",
    "                'rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw', \n",
    "                'RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI', \n",
    "                #'SH3kQeyd5volraxw8vOyhlowNqWBPr1IJ9URNXUL4'] \n",
    "                'VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is', \n",
    "                'Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw', \n",
    "                'XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA', \n",
    "                'YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw', \n",
    "                'ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM', \n",
    "                'ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY']\n",
    "    \n",
    "    # load data\n",
    "    X_test = loadTestData(testFolders)\n",
    "    # transform output to one_hot_encoding for the testing dataset\n",
    "    X_test = transform_output_nominal_class_into_one_hot_encoding(X_test)\n",
    "    # transforms the data\n",
    "    X_test = transform_data_type(X_test)\n",
    "    # selects the data to train and test\n",
    "    X_test_data = X_test[inputFeatures]\n",
    "    y_test_label = X_test[outputClasses]\n",
    " \n",
    "    # The `evaluate` function will be called after every round\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        loss, accuracy = model.evaluate(X_test_data, y_test_label)\n",
    "        print(\"Testa aquiiiiiiiiiiiiiiiiiiiiiiii\", loss, accuracy)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate\n",
    "\t\n",
    "def evaluate_config(server_round: int):\n",
    "    \"\"\"Return evaluation configuration dict for each round.\n",
    "    Perform five local evaluation steps on each client (i.e., use five\n",
    "    batches) during rounds, one to three, then increase to ten local\n",
    "    evaluation steps.\n",
    "    \"\"\"\n",
    "    val_steps = 5 if server_round < 4 else 10\n",
    "    return {\"val_steps\": val_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759cdf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 15:13:35.862373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-19 15:13:35.889880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-07-19 15:13:35.889899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-19 15:13:35.890272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(9,)),\n",
    "      #tf.keras.layers.Dense(9, activation=tf.keras.activations.relu), \n",
    "      tf.keras.layers.Dense(16, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(8, activation=tf.keras.activations.relu),\n",
    "      tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)\n",
    "      #tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)\n",
    "    ])\n",
    "# Load model and data (MobileNetV2, CIFAR-10)\n",
    "model = create_keras_model()\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e94617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 datasets\n",
      "0 - PZCf1nfvhR+6fk+7+sPNMYOgb8BAMmtQtfoRS83Suc\n",
      "1 - rIl2UK9+bQ+tzpFdbJAdbBxEa5GbgrgC030yEaENLw\n",
      "2 - RoBW3cDOO9wWRMPO2twQff83MPc+OXn6gJ+a1DafreI\n",
      "3 - VVpwFNMrEglveh6MDN8lrRzTy5OwzglD4FURfM4A2is\n",
      "4 - Wa1mcNmbh66S7VS6GIzyfCFMD3SGhbtDQyFP1ywJEsw\n",
      "5 - XCKRE0BWRHxfP1kZIihgtT+jUjSp2GE8v5ZlhcIhVmA\n",
      "6 - YI5Y79K6GXqAUoGP6PNyII8WKlAoel4urDxWSVVOvBw\n",
      "7 - ypklj+8GJ15rOIH1lpKQtFJOuK+VdvyCuBPqhY3aoM\n",
      "8 - ZSsAZ0Pq+MCqFrnjsRFn5Ua09pMCVaOV9c8ZuYb7XQY\n"
     ]
    }
   ],
   "source": [
    "# Create strategy and run server\n",
    "strategy = SaveModelStrategy( \n",
    "    # (same arguments as FedAvg here) // https://github.com/adap/flower/blob/main/examples/android/server.py\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=1.0,\n",
    "        min_fit_clients=19,\n",
    "        min_evaluate_clients=19,\n",
    "        min_available_clients=19,        \n",
    "        evaluate_fn=get_evaluate_fn(model), # evaluate_fn=None,\n",
    "        on_fit_config_fn=fit_config,\n",
    "        on_evaluate_config_fn=evaluate_config,\n",
    "        initial_parameters=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50caff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Flower server\n",
    "fl.server.start_server(\n",
    "    server_address=\"0.0.0.0:8099\",\n",
    "    config=fl.server.ServerConfig(num_rounds=30),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1399022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
